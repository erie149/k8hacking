id: sparkSlaveController        #  
kind: ReplicationController     #  KIND: ReplicatoinControllers: Automatic rebalancing POD creators.                                 # These are the idiomatic way to create pods (rather than manually).
apiVersion: v1beta1             #  apiVersion: As always, make sure this is right!
desiredState:                   #  
replicas: 40                    #  replicas: Total number of pods created.
  replicaSelector:              #  if the number is too large, kubernetes will
   name: "spark-slave"          #  throttle this back.
    podTemplate:               
     desiredState:               
      manifest:                
       version: v1beta1          
       id: sparkSlaveController
       containers:                        #  
        - name: "spark-slave"             # 
        - image: "jayunit100/spark7"      #  image: A docker image on your registry. 
        - cpu: 200                        #  cpu: Relative amount of CPU
        - command:                        #  command: This command breaks each argument
         - "/bin/bash"                    #  into a separate YAML element.  Without this,
         - "-c"                           #  you may get very odd breaks in the executed command.
         - "/opt/spk/sbin/start-slave.sh" # 
         - "-h"                              
         - "spark://${SPARK_MASTER_SERVICE}:7077 && tailf logs/*" 
       ports:                              #  SPARK_MASTER_SERVICE is generated by the kubernetes
        - containerPort: 6379              #  daemon at runtime, pointing to the IP of the HA
        - hostPort: 6380                   #  proxy which we define when 
        - labels:                          #  we run spark-master-service.yaml
         - name: "spark-slave"             #  
         - uses: "spark-master"            #  Note as always that the labels here need to match
                                           #  exactly the name of the HA service which is being connected.
